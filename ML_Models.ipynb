{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "- loading dataset and applying preprocessing\n",
    "- Training multiple ML models\n",
    "    - Looking at metrics for comparison of models\n",
    "- Hyperparameter training on best model\n",
    "- Creating submission file (csv) for Kaggle Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset\n",
    "- Using preprocess_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing module that wraps preprocessing steps\n",
    "import Churn_Preprocess as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Churn_Preprocess' from '/Users/Temp/Data3402/Kaggle/Churn_Preprocess.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reimport if necessary (edit file after already imported)\n",
    "import importlib\n",
    "importlib.reload(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset/applying preprocessing\n",
    "df=cp.load_preprocess_data('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Age/Tenure</th>\n",
       "      <th>Balance/Tenure</th>\n",
       "      <th>Balance/Age</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.568720</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.907279</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.471564</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247483</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.592417</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.924364</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.362559</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.593398</td>\n",
       "      <td>0.422787</td>\n",
       "      <td>0.298246</td>\n",
       "      <td>0.336028</td>\n",
       "      <td>0.424012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.682464</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075293</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165029</th>\n",
       "      <td>0.566351</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659179</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>0.862559</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659177</td>\n",
       "      <td>0.204678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165031</th>\n",
       "      <td>0.324645</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.637151</td>\n",
       "      <td>0.108772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>0.298578</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.643819</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>0.075188</td>\n",
       "      <td>0.104166</td>\n",
       "      <td>0.521378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165033</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307880</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165034 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore       Age   Balance  EstimatedSalary  Age/Tenure  \\\n",
       "0          0.568720  0.384615  0.000000         0.907279    0.192982   \n",
       "1          0.471564  0.384615  0.000000         0.247483    0.578947   \n",
       "2          0.592417  0.564103  0.000000         0.924364    0.070175   \n",
       "3          0.362559  0.410256  0.593398         0.422787    0.298246   \n",
       "4          0.682464  0.384615  0.000000         0.075293    0.115789   \n",
       "...             ...       ...       ...              ...         ...   \n",
       "165029     0.566351  0.384615  0.000000         0.659179    0.289474   \n",
       "165030     0.862559  0.435897  0.000000         0.659177    0.204678   \n",
       "165031     0.324645  0.333333  0.000000         0.637151    0.108772   \n",
       "165032     0.298578  0.307692  0.643819         0.355841    0.075188   \n",
       "165033     1.000000  0.333333  0.000000         0.307880    0.543860   \n",
       "\n",
       "        Balance/Tenure  Balance/Age    0    1    2  ...   15   16   17   18  \\\n",
       "0             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "1             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "2             0.000000     0.000000  1.0  0.0  0.0  ...  1.0  0.0  1.0  0.0   \n",
       "3             0.336028     0.424012  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "4             0.000000     0.000000  0.0  0.0  1.0  ...  0.0  0.0  1.0  0.0   \n",
       "...                ...          ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "165029        0.000000     0.000000  0.0  0.0  1.0  ...  0.0  1.0  0.0  0.0   \n",
       "165030        0.000000     0.000000  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "165031        0.000000     0.000000  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "165032        0.104166     0.521378  0.0  0.0  1.0  ...  0.0  1.0  0.0  0.0   \n",
       "165033        0.000000     0.000000  1.0  0.0  0.0  ...  0.0  1.0  0.0  0.0   \n",
       "\n",
       "         19   20   21   22   23  Exited  \n",
       "0       0.0  0.0  1.0  1.0  0.0       0  \n",
       "1       0.0  0.0  1.0  0.0  1.0       0  \n",
       "2       0.0  0.0  1.0  1.0  0.0       0  \n",
       "3       0.0  0.0  1.0  0.0  1.0       0  \n",
       "4       0.0  0.0  1.0  0.0  1.0       0  \n",
       "...     ...  ...  ...  ...  ...     ...  \n",
       "165029  0.0  0.0  1.0  0.0  1.0       0  \n",
       "165030  0.0  1.0  0.0  1.0  0.0       0  \n",
       "165031  0.0  0.0  1.0  0.0  1.0       0  \n",
       "165032  0.0  1.0  0.0  0.0  1.0       0  \n",
       "165033  0.0  0.0  1.0  1.0  0.0       1  \n",
       "\n",
       "[165034 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing ML algorithms for testing\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "]\n",
    "\n",
    "#creating classifier instances for each ML alg\n",
    "classifier_instances = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025, random_state=42),\n",
    "    DecisionTreeClassifier(max_depth=5, random_state=42),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, \n",
    "                           max_features=1, random_state=42),\n",
    "]\n",
    "\n",
    "#creating dictionary of classifier name and instance\n",
    "classifiers = dict(zip(names,classifier_instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over datasets\n",
    "import sys\n",
    "\n",
    "def fit_all(dataset,classifiers, max_cls=None):\n",
    "    scores = dict()\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X = dataset.iloc[:,:-1] #excluding target var\n",
    "    y = dataset.iloc[:,-1:] #only target var\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for cls_cnt,(cls_name, clf) in enumerate(classifiers.items()):\n",
    "        print(cls_cnt,\"Running classifier\",cls_name,\"on dataset\",\". N_Train = \",X_train.shape[0] )\n",
    "        sys.stdout.flush()\n",
    "        clf_0 = make_pipeline(StandardScaler(), clf)\n",
    "        clf_0.fit(X_train.to_numpy(), y_train.to_numpy().reshape((len(y_train),)))\n",
    "        score = clf.score(X_test.to_numpy(), y_test.to_numpy())\n",
    "\n",
    "        scores[cls_name]=dict()\n",
    "        scores[cls_name]['Score'] = score\n",
    "        scores[cls_name]['Accuracy']=accuracy_score(y_test.to_numpy(),clf_0.predict(X_test.to_numpy()))\n",
    "        scores[cls_name]['Precision']=precision_score(y_test.to_numpy(),clf_0.predict(X_test.to_numpy()))\n",
    "        scores[cls_name]['Recall']=recall_score(y_test.to_numpy(),clf_0.predict(X_test.to_numpy()))\n",
    "        scores[cls_name]['F1']=f1_score(y_test.to_numpy(),clf_0.predict(X_test.to_numpy()))\n",
    "        scores[cls_name]['AUC-ROC']=roc_auc_score(y_test.to_numpy(),clf_0.predict(X_test.to_numpy()))\n",
    "        if max_cls:\n",
    "            if cls_cnt>max_cls:\n",
    "                print(\"Max Classifiers Reached.\")\n",
    "                sys.stdout.flush()\n",
    "                break\n",
    "\n",
    "\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Running classifier Nearest Neighbors on dataset . N_Train =  115523\n",
      "1 Running classifier Linear SVM on dataset . N_Train =  115523\n",
      "2 Running classifier Decision Tree on dataset . N_Train =  115523\n",
      "3 Running classifier Random Forest on dataset . N_Train =  115523\n",
      "Max Classifiers Reached.\n"
     ]
    }
   ],
   "source": [
    "scores = fit_all(df,classifiers,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                 </th><th style=\"text-align: right;\">   Score</th><th style=\"text-align: right;\">  Accuracy</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">    Recall</th><th style=\"text-align: right;\">        F1</th><th style=\"text-align: right;\">  AUC-ROC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Nearest Neighbors</td><td style=\"text-align: right;\">0.788855</td><td style=\"text-align: right;\">  0.835976</td><td style=\"text-align: right;\">   0.631328</td><td style=\"text-align: right;\">0.52274   </td><td style=\"text-align: right;\">0.571926  </td><td style=\"text-align: right;\"> 0.720893</td></tr>\n",
       "<tr><td>Linear SVM       </td><td style=\"text-align: right;\">0.790895</td><td style=\"text-align: right;\">  0.860071</td><td style=\"text-align: right;\">   0.739717</td><td style=\"text-align: right;\">0.512912  </td><td style=\"text-align: right;\">0.605781  </td><td style=\"text-align: right;\"> 0.732525</td></tr>\n",
       "<tr><td>Decision Tree    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.854457</td><td style=\"text-align: right;\">   0.748278</td><td style=\"text-align: right;\">0.46059   </td><td style=\"text-align: right;\">0.570202  </td><td style=\"text-align: right;\"> 0.70975 </td></tr>\n",
       "<tr><td>Random Forest    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.790754</td><td style=\"text-align: right;\">   1       </td><td style=\"text-align: right;\">0.00173444</td><td style=\"text-align: right;\">0.00346287</td><td style=\"text-align: right;\"> 0.500867</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "display(HTML(tabulate.tabulate(list(map(lambda x: [x[0]]+x[1],zip(scores.keys(),map(lambda x: list(x.values()),scores.values())))), \n",
    "                               tablefmt='html',\n",
    "                               headers=[\" \"]+list(next(iter(scores.items()))[1].keys()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of best metric to evaluate models\n",
    "- Accuracy: Not a good metric when dataset is imbalanced like this one\n",
    "- Precision: Good for when false positives are important\n",
    "- Recall: Good for when false negatives are important\n",
    "- F1: The harmonic mean of precisuion and recall, good for imbalanced datasets\n",
    "- AUC_ROC: TPR v. FPR, good for imbalanced datasets\n",
    "\n",
    "Due to the Churn dataset being imbalanced, Exited being minority class, F1 and AUC_ROC scores will give the best indicator as to how good the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of Results\n",
    "- The Linear SVM has the best F1 and AUC_ROC scores of the models trained.\n",
    "- It is interesting and concerning that the Random Forest model had a precision score of 1, indicating it perfectly was predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning on SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting\n",
    "df.columns=df.columns.astype(str) \n",
    "\n",
    "# 'Exited' is the target variable\n",
    "X = df.drop(columns=['Exited'])\n",
    "y = df['Exited']\n",
    "\n",
    "# Splitting the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.857 total time= 5.1min\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.861 total time= 4.8min\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.859 total time= 5.1min\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.857 total time= 4.9min\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.861 total time= 5.0min\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.859 total time= 4.8min\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.857 total time= 4.8min\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.861 total time= 4.8min\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.859 total time= 5.3min\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.857 total time= 4.8min\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.861 total time= 5.6min\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.859 total time= 5.0min\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.859 total time= 4.9min\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.859 total time= 4.8min\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.857 total time= 5.5min\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.861 total time= 5.2min\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.859 total time= 5.1min\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.859 total time= 5.6min\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.860 total time= 5.4min\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.857 total time= 5.5min\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.861 total time= 5.3min\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.859 total time= 5.2min\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.859 total time= 5.2min\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.860 total time= 5.4min\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.857 total time= 5.6min\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.861 total time= 5.3min\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.859 total time= 5.2min\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.859 total time= 5.3min\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.860 total time= 5.6min\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.857 total time= 5.6min\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.861 total time= 5.4min\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.859 total time= 5.1min\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.859 total time= 5.2min\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.860 total time= 5.8min\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.857 total time= 8.7min\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.861 total time= 8.6min\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.859 total time= 8.7min\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.859 total time= 8.6min\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.859 total time= 9.0min\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.857 total time= 8.6min\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.861 total time= 8.7min\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.859 total time= 9.0min\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.859 total time= 8.7min\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.859 total time= 8.9min\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.857 total time= 8.8min\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.861 total time= 8.7min\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.859 total time= 8.5min\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.859 total time= 9.2min\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.859 total time= 9.1min\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.857 total time= 8.6min\n",
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.861 total time= 8.8min\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.859 total time= 8.9min\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.859 total time= 8.6min\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.859 total time= 9.0min\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.857 total time=31.8min\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.861 total time=32.7min\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.859 total time=32.9min\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.859 total time=32.3min\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.860 total time=32.9min\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.857 total time=31.7min\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.861 total time=32.6min\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.859 total time=33.2min\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.859 total time=32.9min\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.860 total time=32.9min\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.857 total time=33.8min\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.861 total time=32.9min\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.859 total time=33.1min\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.859 total time=32.6min\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.860 total time=33.4min\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.857 total time=32.4min\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.861 total time=32.9min\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.859 total time=33.0min\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.859 total time=32.9min\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.860 total time=32.9min\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['linear']}  \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                 </th><th style=\"text-align: right;\">   Score</th><th style=\"text-align: right;\">  Accuracy</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">    Recall</th><th style=\"text-align: right;\">        F1</th><th style=\"text-align: right;\">  AUC-ROC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Nearest Neighbors</td><td style=\"text-align: right;\">0.788855</td><td style=\"text-align: right;\">  0.835976</td><td style=\"text-align: right;\">   0.631328</td><td style=\"text-align: right;\">0.52274   </td><td style=\"text-align: right;\">0.571926  </td><td style=\"text-align: right;\"> 0.720893</td></tr>\n",
       "<tr><td>Linear SVM       </td><td style=\"text-align: right;\">0.790895</td><td style=\"text-align: right;\">  0.860071</td><td style=\"text-align: right;\">   0.739717</td><td style=\"text-align: right;\">0.512912  </td><td style=\"text-align: right;\">0.605781  </td><td style=\"text-align: right;\"> 0.732525</td></tr>\n",
       "<tr><td>Decision Tree    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.854457</td><td style=\"text-align: right;\">   0.748278</td><td style=\"text-align: right;\">0.46059   </td><td style=\"text-align: right;\">0.570202  </td><td style=\"text-align: right;\"> 0.70975 </td></tr>\n",
       "<tr><td>Random Forest    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.790754</td><td style=\"text-align: right;\">   1       </td><td style=\"text-align: right;\">0.00173444</td><td style=\"text-align: right;\">0.00346287</td><td style=\"text-align: right;\"> 0.500867</td></tr>\n",
       "<tr><td>SVC HPT          </td><td style=\"text-align: right;\">0.865949</td><td style=\"text-align: right;\">  0.860112</td><td style=\"text-align: right;\">   0.739589</td><td style=\"text-align: right;\">0.513394  </td><td style=\"text-align: right;\">0.606074  </td><td style=\"text-align: right;\"> 0.732727</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtaining the best performing model from the grid search results\n",
    "best = grid.best_estimator_\n",
    "\n",
    "# predictions\n",
    "y_pred = best.predict(X_test)\n",
    "\n",
    "# metrics; adding SVC hyperparameter tuning scores to existing scores dictionary\n",
    "scores['SVC HPT']=dict()\n",
    "scores['SVC HPT']['Score'] = best_model.score(X_test,y_test)\n",
    "scores['SVC HPT']['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "scores['SVC HPT']['Precision'] = precision_score(y_test, y_pred)\n",
    "scores['SVC HPT']['Recall'] = recall_score(y_test, y_pred)\n",
    "scores['SVC HPT']['F1'] = f1_score(y_test, y_pred)\n",
    "scores['SVC HPT']['AUC-ROC'] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "#table of metrics for previous models + SVC hyperparameter tuning\n",
    "display(HTML(tabulate.tabulate(list(map(lambda x: [x[0]]+x[1],zip(scores.keys(),map(lambda x: list(x.values()),scores.values())))), \n",
    "                               tablefmt='html',\n",
    "                               headers=[\" \"]+list(next(iter(scores.items()))[1].keys()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "xgb_classifier = xgb.XGBClassifier()\n",
    "xgb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation AUC Scores: [0.88061045 0.88152119 0.88407218 0.88075421 0.88539683]\n",
      "Mean AUC Score: 0.8824709725452845\n"
     ]
    }
   ],
   "source": [
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(xgb_classifier, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-Validation AUC Scores:\", cv_scores)\n",
    "print(\"Mean AUC Score:\", cv_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=3, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=4, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.1s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   1.7s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   1.6s\n",
      "[CV] END ..learning_rate=0.01, max_depth=4, n_estimators=200; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.01, max_depth=5, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   2.2s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   2.9s\n",
      "[CV] END ..learning_rate=0.01, max_depth=5, n_estimators=200; total time=   1.8s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=3, n_estimators=50; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=100; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   2.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   2.0s\n",
      "[CV] END ...learning_rate=0.1, max_depth=3, n_estimators=200; total time=   1.3s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.1, max_depth=4, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=100; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...learning_rate=0.1, max_depth=4, n_estimators=200; total time=   1.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.7s\n",
      "[CV] END ....learning_rate=0.1, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   1.1s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=100; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END ...learning_rate=0.1, max_depth=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END ....learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.3, max_depth=3, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=100; total time=   0.7s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.2s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=3, n_estimators=200; total time=   1.5s\n",
      "[CV] END ....learning_rate=0.3, max_depth=4, n_estimators=50; total time=   0.5s\n",
      "[CV] END ....learning_rate=0.3, max_depth=4, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.3, max_depth=4, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=100; total time=   1.0s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=100; total time=   0.8s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...learning_rate=0.3, max_depth=4, n_estimators=200; total time=   1.3s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ....learning_rate=0.3, max_depth=5, n_estimators=50; total time=   0.6s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=100; total time=   0.9s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END ...learning_rate=0.3, max_depth=5, n_estimators=200; total time=   1.4s\n",
      "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.3]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>                 </th><th style=\"text-align: right;\">   Score</th><th style=\"text-align: right;\">  Accuracy</th><th style=\"text-align: right;\">  Precision</th><th style=\"text-align: right;\">    Recall</th><th style=\"text-align: right;\">        F1</th><th style=\"text-align: right;\">  AUC-ROC</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Nearest Neighbors</td><td style=\"text-align: right;\">0.788855</td><td style=\"text-align: right;\">  0.835976</td><td style=\"text-align: right;\">   0.631328</td><td style=\"text-align: right;\">0.52274   </td><td style=\"text-align: right;\">0.571926  </td><td style=\"text-align: right;\"> 0.720893</td></tr>\n",
       "<tr><td>Linear SVM       </td><td style=\"text-align: right;\">0.790895</td><td style=\"text-align: right;\">  0.860071</td><td style=\"text-align: right;\">   0.739717</td><td style=\"text-align: right;\">0.512912  </td><td style=\"text-align: right;\">0.605781  </td><td style=\"text-align: right;\"> 0.732525</td></tr>\n",
       "<tr><td>Decision Tree    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.854457</td><td style=\"text-align: right;\">   0.748278</td><td style=\"text-align: right;\">0.46059   </td><td style=\"text-align: right;\">0.570202  </td><td style=\"text-align: right;\"> 0.70975 </td></tr>\n",
       "<tr><td>Random Forest    </td><td style=\"text-align: right;\">0.79039 </td><td style=\"text-align: right;\">  0.790754</td><td style=\"text-align: right;\">   1       </td><td style=\"text-align: right;\">0.00173444</td><td style=\"text-align: right;\">0.00346287</td><td style=\"text-align: right;\"> 0.500867</td></tr>\n",
       "<tr><td>SVC HPT          </td><td style=\"text-align: right;\">0.865949</td><td style=\"text-align: right;\">  0.860112</td><td style=\"text-align: right;\">   0.739589</td><td style=\"text-align: right;\">0.513394  </td><td style=\"text-align: right;\">0.606074  </td><td style=\"text-align: right;\"> 0.732727</td></tr>\n",
       "<tr><td>XGBoost          </td><td style=\"text-align: right;\">0.865949</td><td style=\"text-align: right;\">  0.865949</td><td style=\"text-align: right;\">   0.74667 </td><td style=\"text-align: right;\">0.545577  </td><td style=\"text-align: right;\">0.630477  </td><td style=\"text-align: right;\"> 0.748244</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Obtaining the best performing model from the grid search results\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# metrics; adding XGBoost scores to existing scores dictionary\n",
    "scores['XGBoost']=dict()\n",
    "scores['XGBoost']['Score'] = best_model.score(X_test,y_test)\n",
    "scores['XGBoost']['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "scores['XGBoost']['Precision'] = precision_score(y_test, y_pred)\n",
    "scores['XGBoost']['Recall'] = recall_score(y_test, y_pred)\n",
    "scores['XGBoost']['F1'] = f1_score(y_test, y_pred)\n",
    "scores['XGBoost']['AUC-ROC'] = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "#table of metrics for previous models + XGB\n",
    "display(HTML(tabulate.tabulate(list(map(lambda x: [x[0]]+x[1],zip(scores.keys(),map(lambda x: list(x.values()),scores.values())))), \n",
    "                               tablefmt='html',\n",
    "                               headers=[\" \"]+list(next(iter(scores.items()))[1].keys()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHFCAYAAAAOmtghAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABc9UlEQVR4nO3deVxU5f4H8M/AMMMOKoIgi7igmDuUotdMU0z7aVomJpV7kS0q17x6vbm0aLdyzbU0zULF3NJyo3LXm4qaJpQbCiqIuLDIOvD8/jgw48giAzNzZPi8X695xTznzJnvHMz5+JznPI9CCCFAREREZCGs5C6AiIiIyJgYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYbogszMiRI6FWq3H27NlS2z799FMoFAps375drz0jIwOffvopOnbsCFdXV9jY2MDDwwPPPfcc1q5di7y8PO2+V65cgUKh0Hs4Ozujbdu2mD9/PgoLCx9Z44wZM/Reb2NjA19fX4wZMwYpKSllvub+/fv49NNP0b59ezg6OsLBwQHt2rXDrFmzcP/+/TJfk5eXh0WLFuEf//gH6tSpA5VKhYYNG2Lw4MHYv3//I+ssOTeffPIJgoOD4ezsDLVajUaNGmHkyJE4efJkpY5BRGYmiMiipKenC19fX9G+fXuRn5+vbT9z5oxQqVRi+PDhevufP39eNG7cWDg6OorIyEjx448/igMHDojo6GgxcuRIoVarxX/+8x/t/gkJCQKAePfdd8XRo0fF0aNHxc6dO8Vbb70lAIjIyMhH1jh9+nQBQOzatUscPXpUxMTEiPfff19YWVmJli1b6tUthBApKSmiVatWws7OTvzrX/8Se/bsEXv27BGTJ08WdnZ2olWrViIlJUXvNbdu3RJBQUHCxsZGvPnmm2Lr1q3iwIEDYt26dWLIkCHC2tpanD59usI6L168qD03EydOFD/99JPYt2+fWL16tejbt68AIO7du/fIz0tE5sVwQ2SBYmJihEKhENOmTRNCCJGfny/atm0rfHx89L6MCwoKRMuWLYWrq6uIi4sr81hXrlwRW7Zs0T4vCTeff/55qX27du0qPD09H1lfSbi5deuWXvuIESMEAPHbb7/ptYeGhgqlUikOHjxY6lgHDx4USqVS9O7dW6+9T58+QqlUil9//bXMGo4dOyauXr1abo0ajUa0bt1aODs7i7Nnz5a5z44dO8T9+/fLPUZlFRUViezs7Gofh4gkvCxFZIF69uyJiIgIzJo1C7GxsZgxYwb++OMPrFy5Ei4uLtr9tmzZgri4OEydOhWBgYFlHsvPzw8DBgyo1Pu6uLjAxsamynUHBwcDAG7evKltO3HiBPbs2YNRo0bhH//4R6nX/OMf/8DIkSOxe/duxMbGAgBiY2Oxc+dOjBo1Cj169CjzvZ588kn4+vqWW8vWrVtx9uxZTJkyBa1atSpznz59+sDe3h4AMHz4cDRq1KjUPiWX4B6kUCjwzjvvYNmyZQgMDIRarcaKFSvg7u6O1157rdQx7t27Bzs7O0RGRmrbMjIyMHHiRPj7+2svt40fP77cS3REtYlS7gKIyDQ+//xz7N69G4MGDUJSUhIiIiLQq1cvvX1iYmIAAP379zf4+EVFRdBoNACA9PR0/Pjjj9i1axf+9a9/VbnmhIQEAEBAQECpGisKWAMGDMBXX32FmJgYBAUFYc+ePY98zaMY4xgV2bp1Kw4ePIhp06ahQYMGcHd3R0JCApYtW4bFixfD2dlZu++6deuQm5uLESNGAACys7PRrVs3XLt2Df/+97/Rpk0bnDt3DtOmTcPZs2fxyy+/lApURLUJww2RhXJwcMDHH3+MoUOHokGDBvj8889L7ZOUlARA6p15kBBCb2CwQqGAtbW13j7/+te/SgWZ4cOHY+bMmZWusbCwEBqNBllZWYiJicHSpUvxyiuvoEOHDtp9EhMTAQD+/v7lHqdkW8m+lXnNoxjjGBXJysrC2bNnUadOHW3biBEjMG/ePERHR2PMmDHa9tWrVyMoKAitW7cGACxcuBBnzpzB77//ru3tevbZZ9GwYUMMGjQIu3btQp8+fUxSN1FNwMtSRBaqqKgIX375JaysrJCamoo//vij0q9dsGABbGxstI+2bduW2mfcuHE4fvw4jh8/jr1792LWrFnYsGEDXnnllUq/T4MGDWBjY4M6depg8ODBCAoKwrffflvp15cQQgBAjeqt6NGjh16wAYDWrVsjKCgIq1at0rbFx8fj2LFjGDlypLbtp59+QqtWrdCuXTtoNBrto3fv3lAoFNi3b5+5PgbRY4nhhshCffHFFzh69CjWrl2LZs2aYeTIkcjJydHbp2TMydWrV/Xahw4dqg0uD/aiPMjb2xvBwcEIDg7GM888gylTpuCDDz7ADz/8gN27d1eqxl9++QXHjx/H7t278dJLL+HAgQN49913y6yx5JJVWa5cuQIA8PHxqfRrHsUYx6iIp6dnme0jR47E0aNH8ddffwEAVq1aBbVarRcab968iTNnzugFUBsbGzg5OUEIgbS0NJPUTFRTMNwQWaC4uDhMmzYNr7/+OsLCwrB69WpcvHgRU6dO1duvZAzOtm3b9Nrd3d21wcXJyanS79umTRsAqHQvUdu2bREcHIzQ0FD88MMP6NWrF7766iscP368VI1bt24t9zgl20r27d279yNf8yiGHsPW1lZvPqAS5QWN8nqZXnnlFajVaqxevRqFhYX47rvvMGDAAL1eHjc3N7Ru3VobQB9+fPDBB5WqmchiyXy3FhEZWUFBgQgODhYNGzYUd+/e1bZPnDhRWFlZiUOHDmnbNBqNaNmypahTp46Ij48v83jdunUTTzzxhPZ5RbeCf/LJJwKAWLVqVYU1lncr+Pnz54VSqRShoaF67SW3gj9Ye4mSW8Gfe+45vfZH3Qp+/Pjxat8KvmvXLu2t4LNnzxZWVlZ68+3k5eWJpk2biof/qgUg3n777XLfOywsTHh6eoqtW7cKAGL37t162z/++GNhb28vLl++XO4xiGozhhsiC/Phhx8KAGLnzp167Tk5OaJ58+YiICBAb06V8+fPC39/f+Hk5CQiIyPFtm3bxMGDB8X27dvFf/7zH+Hq6ipCQkK0+5c1id8vv/wiPvroI2Fvby/8/PxEenp6hTWWF26EEGLs2LECgN6cNiWT+Nnb24vJkyeLmJgYERMTI6ZMmSLs7e0rnMRPpVKJiIgIvckJX331VYMn8Xv//ffFjh07xP79+8WaNWtE//79hUKh0M4bdPnyZWFjYyOeeeYZ8fPPP4tNmzaJbt26CX9/f4PDze7duwUA4e3tLby9vUVhYaHe9qysLNG+fXvh7e0t5syZI2JiYsTu3bvF119/LV5++WXxv//9r8LPRWTpGG6ILMjp06eFjY2NGDNmTJnbjx49KqysrMSECRP02tPT08WsWbPEk08+KZydnYVSqRTu7u6iV69eYvHixXoT1ZWEmwcftra2IiAgQIwfP14kJyc/ss6Kws3NmzeFo6Oj6N69u157VlaWmDVrlmjXrp2wt7cX9vb2ok2bNuLjjz8WWVlZZb5PTk6OWLhwoQgJCdF+Li8vL/Hiiy+Kn3/++ZF1CiHEvXv3xEcffSQ6dOggHB0dhY2NjfD19RWvvvqqOHz4sN6+O3bsEO3atRN2dnaicePGYtGiRdrP+qBHhZvCwkLh4+MjAIipU6eWuU9WVpb4z3/+I5o3by5UKpVwcXERrVu3FhMmTCgV9IhqG4UQxbcZEBEREVkADigmIiIii8JwQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkUWrdquBFRUW4ceMGnJycatQie0RERLWZEAKZmZnw8vKClVXFfTO1LtzcuHFDu7geERER1SxJSUnw9vaucJ9aF25KFgFMSkqCs7OzzNUQERFRZWRkZMDHx6dSi/nWunBTcinK2dmZ4YaIiKiGqcyQEg4oJiIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWRdZwc+DAAfTr1w9eXl5QKBTYunXrI1+zf/9+BAUFwdbWFo0bN8ayZctMXygRERHVGLKGm/v376Nt27ZYtGhRpfZPSEhA37590bVrV5w6dQr//ve/8d5772HTpk0mrpSIiIhqClkXzuzTpw/69OlT6f2XLVsGX19fzJ8/HwAQGBiIEydO4IsvvsBLL71koiqJiIio0rJvAZnXAI/2spVQo8bcHD16FKGhoXptvXv3xokTJ1BQUFDma/Ly8pCRkaH3ICIiIiMquA/ErwU2Pw8s9wJ2j5C1HFl7bgyVkpICDw8PvTYPDw9oNBqkpaXB09Oz1Gtmz56NmTNnmqtEIiKi2qFIA1z9BYiPAi5ukQJOCSslkJcOqF1kKa1GhRsAUCgUes+FEGW2l5gyZQoiIyO1zzMyMuDj42O6AomIiCyVEEDKMSnQ/B0NZKfqtrk0BgKHAi3CgXot5KsRNSzcNGjQACkpKXptqampUCqVqFevXpmvUavVUKvV5iiPiIjIMt29IAWa+Cjg3kVdu50b0DwMCAwHPDsB5XQ0mFuNCjchISHYvn27XtuePXsQHBwMGxsbmaoiIiKyQPdvAn+vlwJNynFdu9IOaDpACjR+oYD14/f9K2u4ycrKwsWLugSYkJCA06dPo27duvD19cWUKVNw/fp1rFmzBgAQERGBRYsWITIyEmPGjMHRo0excuVKrFu3Tq6PQEREZDnyM4GLW4G474HEXwBRJLUrrAG/XlKgaToAUDnKWeUjyRpuTpw4ge7du2ufl4yNGTZsGFavXo3k5GQkJiZqt/v7+2PHjh2YMGECFi9eDC8vLyxcuJC3gRMREVVVYQFwZbfUQ3PpR0CTo9vW4Ckp0DQPAxw8yj/GY0YhSkbk1hIZGRlwcXFBeno6nJ2d5S6HiIjI/IQAbhwF4r8H/t4A5N7WbavTTBoUHDhU+vkxYcj3d40ac0NERETVcDte6qH5ay2QnqBrt3cHWrwi9dJ4BD82A4OriuGGiIjIkmXdAP5aJ4Wa1FO6dhtHoNlAKdD4PivNTWMhLOeTEBERkSQvHbiwWQo0ib8BKB6BYqUEGj0nBZom/QEbe1nLNBWGGyIiIkugyQMSdgJ/RQGXtgOFebptXp2lQBMwGLB3k69GM2G4ISIiqqlEEXD9kNRDc/4HIPeublvdFkDgq9LAYBd/+WqUAcMNERFRTXPrbPHA4HVApm7KFDh46gYGu7ev8QODq4rhhoiIqCbISCoeGPw9kHZW165yApoNkgKNzzOAlbVsJT4uGG6IiIgeV7l3gfMbpV6aawegGxhsA/j3lQJN4/8DbOxkLfNxw3BDRET0ONHkApd/lgJNws9AYb5um/fTUqBpNgiwqytfjY85hhsiIiK5FRUC1/ZLgebCJulW7hJurYpnDH4FcPaTr8YahOGGiIhIDkIAt/7QDQzOuq7b5ugt3eUUGA7UbyNfjTUUww0REZE5pV+Rlj+IjwJux+na1a5AwMtSoPHuCiis5KqwxmO4ISIiMrWc29IClfFRwI3DunZrtTQgODBcGiCsVMtXowVhuCEiIjKFgmxppuD4KODKTqBIU7xBAfh2l8bRNHsRsHWVs0qLxHBDRERkLEUaaS2n+ChpbaeCLN22+u2kHpoWrwBODWUrsTZguCEiIqoOIYCbsVKg+Xs9cD9Ft83ZTwo0geFAvZby1VjLMNwQERFVxb1LUqCJjwLunte129YFmg+WLjs17MyBwTJguCEiIqqs7FvA39FSoEn+n65daQs0eUHqoWnUG7BWyVcjMdwQERFVqOA+cHFr8cDgPYAolNoVVoDvs1KgaToQUDvLWibpMNwQERE9rEgDXI0pHhi8BdBk67Z5BEuBpnkY4OgpX41ULoYbIiIiQBoYnPx78cDgaCDnlm6bS2PdwOC6zeWrkSqF4YaIiGq3O+eLl0CIkgYJl7CrL/XOBIYDnh0BhUK+GskgDDdERFT73E8B/lovhZqbJ3TtSnug2UAp0Pj2BKxt5KuRqozhhoiIaof8TGlivfgoIPFXQBRJ7QproFGoFGiavACoHOWtk6qN4YaIiCxXYT5wZbcUaC5tAzQ5um2eHYHAV6U5aezd5auRjI7hhoiILIsQwI0jxQODNwC5t3Xb6gQUL4EwFKjTVL4ayaQYboiIyDLcjiueMXgtkHFF127vIa3nFBgOeARxYHAtwHBDREQ1V+Z14K91Uqi5dVrXbuMorbgdGA749gCs+HVXm/C3TURENUteOnB+k3TrduJeAEJqt1ICjfoUDwzuB9jYy1omyYfhhoiIHn+aPCBhh9RDc/knoDBPt82rixRoAl4G7N3kq5EeGww3RET0eBJFwLWDUqA5/wOQd0+3rV5L3cBgl0ZyVUiPKYYbIiJ6vNw6Uzxj8DogM0nX7uglhZnAcKB+Ww4MpnIx3BARkfwyEosHBn8PpP2pa1c5AwGDpEDj3Q2wspavRqoxGG6IiEgeuXely03xUcC1A7p2axXg31eaYK/x84DSVr4aqUZiuCEiIvPR5EoDguOjgMs/A0UFum3e3YoHBg8CbOvIVyPVeAw3RERkWkWFQNI+KdBc2ATkZ+i2ubWWemhavAI4+8hVIVkYhhsiIjI+IYDU08VLIKwDsm7otjn5PDAwuLVsJZLlYrghIiLjSU+Qlj+IjwLuxOva1a7SApWB4UDDfwAKK9lKJMvHcENERNWTnQac3yAFmhtHdO3Wammm4BbhgH8fQKmWr0aqVRhuiIjIcAXZwKVtUqC5sgso0hRvUEhrOQWGS2s7qV1kLZNqJ4YbIiKqnCINkPhr8cDgLUBBlm6be3sp0DQfAjg1lK9GIjDcEBFRRYQAbp4onjF4PZB9U7fNuZEUaALDgXqBspVI9DCGGyIiKu3uxeJAsxa4e17XblsPaB4mBRqvEC6BQI8lhhsiIpJkpwJ/RQN/RQHJv+valXZAkxekQNOoN2BtI1+NRJXAcENEVJvlZwEXt0q9NFdjAFEotSusAN+exQODBwIqJ1nLJDIEww0RUW1TWCAFmfgoKdhosnXbGjxZPDA4DHBoIFuJRNXBcENEVBsIAST/r3jG4GggJ023zbVJ8RIIQ4G6AfLVSGQkDDdERJbs9l/SGJr4tUD6ZV27XX2gxRCpl6bBUxwYTBaF4YaIyNJkJQN/r5d6aW7G6tptHICmA6VA49cTsOJXAFkm/skmIrIEeRnAxS1A3PdA0m+AKJLaFdbSHU6B4UDTF6SAQ2ThGG6IiGqqwnwgYZfUQ3N5G6DJ1W3zDCkeGDwYsK8vX41EMmC4ISKqSUQRcP0IEP89cP4HIPeOblud5sUzBg+VBgkT1VIMN0RENUHaOd2MwRlXde0ODYAWr0ihxr0DBwYTgeGGiOjxlXkN+GudFGpu/aFrVzlJK24Hvgr4dAesrOWrkegxxHBDRPQ4yb0HXNgkBZqkfQCE1G5lA/j3kXpoGvcDbOzkq5HoMcdwQ0QkN00ekPBz8cDgn4HCPN22hv+QAk3Ay4BdPflqJKpBrOQuYMmSJfD394etrS2CgoJw8ODBCvePiopC27ZtYW9vD09PT4wYMQK3b982U7VEREYiiqSemT1jgGUewLaXgAubpWBT7wngH7OA0QnAkINA2wgGGyIDyNpzEx0djfHjx2PJkiXo0qULli9fjj59+iAuLg6+vr6l9j906BBef/11zJs3D/369cP169cRERGB0aNHY8uWLTJ8AiIiAwgB3DpTPDB4HZB1TbfNsaG0/EFgOFC/DQcGE1WDQggh5Hrzjh07okOHDli6dKm2LTAwEAMGDMDs2bNL7f/FF19g6dKluHTpkrbtyy+/xGeffYakpKRKvWdGRgZcXFyQnp4OZ2fn6n8IIqJHyUiUlj+I/x64fU7XrnYBmg2SAo330xwYTFQBQ76/Zeu5yc/PR2xsLCZPnqzXHhoaiiNHjpT5ms6dO2Pq1KnYsWMH+vTpg9TUVGzcuBHPP/98ue+Tl5eHvDzd9euMjAzjfAAioork3JHmoYmPAq4/cLndWgU0/j8p0Pj3BZS28tVIZKFkCzdpaWkoLCyEh4eHXruHhwdSUlLKfE3nzp0RFRWFsLAw5ObmQqPRoH///vjyyy/LfZ/Zs2dj5syZRq2diKhMBTnA5Z+kQJOwAygqKN6gAHy6AS3CgYCXANs6spZJZOlkH1CseOi6shCiVFuJuLg4vPfee5g2bRpiY2Oxa9cuJCQkICIiotzjT5kyBenp6dpHZS9fERFVSlEhcPUXYNcIaWDwT4OBSz9KwaZ+W+Dpz4A3EoHBe4E2oxlsiMxAtp4bNzc3WFtbl+qlSU1NLdWbU2L27Nno0qUL3n//fQBAmzZt4ODggK5du+Ljjz+Gp6dnqdeo1Wqo1WrjfwAiqr2EAFJPSWNo/loP3E/WbXPylZY/CAwH3FrJVyNRLSZbuFGpVAgKCkJMTAwGDhyobY+JicELL7xQ5muys7OhVOqXbG0tDcCTcVw0EdUW9y5Lyx/ERwF3/tK129YBAgZLgaZhF0Ahe6c4Ua0m663gkZGReO211xAcHIyQkBB89dVXSExM1F5mmjJlCq5fv441a9YAAPr164cxY8Zg6dKl6N27N5KTkzF+/Hg89dRT8PLykvOjEJGlyr4F/L1BCjTJR3XtSltppuDAcGnmYGuVfDUSkR5Zw01YWBhu376NDz/8EMnJyWjVqhV27NgBPz8/AEBycjISExO1+w8fPhyZmZlYtGgR/vnPf8LV1RU9evTAf//7X7k+AhFZooL7wMVtwF9RwJXdQJFGaldYAT49pEDT7EVAzekkiB5Hss5zIwfOc0NEZSrSAIm/AnHfAxe3SAGnhHsHKdC0GAI4speYSA41Yp4bIiLZCQGkHJcuOf29HshO1W1z8S8ONOFAvRby1UhEBmO4IaLa5+6F4iUQ1ko/l7BzA5qHSaHGsxOXQCCqoRhuiKh2uH8T+DtaCjUpx3TtSjug6QAp0PiFAtY2spVIRMbBcENElis/Sxo/Ex8lTbQnCqV2hTXg10sKNE0HACpHWcskIuNiuCEiy1JYAFzdIwWai1sBTY5uW4OnpEDTPAxwKHuyUCKq+RhuiKjmEwK4cVQKNOc3ADlpum11mkmDggOHSj8TkcVjuCGimut2vG5gcHqCrt3eHWg+ROqlafAkBwYT1TIMN0RUs2TdkNZzio8CUk/q2m0cpIn1AsMB32cBK/71RlRb8f9+Inr85WUAFzZLC1Um/gageO5RKyXQqLd02alpfyngEFGtx3BDRI+nwnwgYafUQ3N5O6DJ1W3z6iz10AQMBuzd5KuRiB5LDDdE9PgQRcD1w1IPzfkfgNy7um11WwCBr0oDg1385auRiB57DDdEJL+0P6Uemvi1QKZusVw4eAItXpF6adzbc2AwEVUKww0RySMjCfhrnbTy9q0zunaVE9BskBRofJ4BrKxlK5GIaiaGGyIyn9x7wPmNUqBJ2g/dwGAbwL+vFGga/x9gYydnlURUwzHcEJFpaXKByz9Ll50SfpYGCpfwfloKNM0GAXZ15auRiCwKww0RGZ8oknpm4r8HLmwC8tJ129xaFc8Y/Arg7CdfjURksRhuiMg4hABu/VE8Y/A6IOu6bpujt3SXU2A4UL+NfDUSUa3AcENE1ZNxVbrLKT4KuH1O1652BQKKBwZ7Pw0orGQrkYhqF4YbIjJczm1pHpr4KOD6IV27tVoaEBwYLg0QVqrlq5GIai2GGyKqnIIcaabguO+BK7uAooLiDQrplu3AcKDZS4Ctq4xFEhEx3BBRRYoKpbWc/oqS1nbKz9Rtq99OCjQthgBO3rKVSET0MIYbItInhLTadtz3wN/rgfspum3OflKgCQwH6rWUr0Yiogow3BCR5N4l3cDgu3/r2m3rAs0HS7dvN+zMgcFE9NhjuCGqzbJvAX9HS4Em+X+6dqUt0OQFqYemUW/AWiVfjUREBmK4IaptCu4DF3+UAs2V3YAolNoVVoDvs1KgaToQUDvLWycRURUx3BDVBkUa4GqMFGgubpUCTgmPICDwVaB5GODoKVuJRETGwnBDZKmEAFKOSYHm72ggO1W3zaWxbmBw3eby1UhEZAIMN0SW5s754iUQ1gL3Lura7epLvTOB4YBnR0ChkK9GIiITYrghsgT3U3QDg1OO69qV9kDTAVKg8esFWNvIViIRkbkw3BDVVPmZwIUtUqBJ/EVaiRsAFNZAo1Ap0DR5AVA5ylsnEZGZMdwQ1SSFBdIdTvHfA5e2AZoc3TbPjtJcNC3CAHt3+WokIpIZww3R404I4MaR4oHBG4Dc27ptdQKKl0AYCtRpKl+NRESPEYYbosfV7Tgp0MSvBTKu6NrtPYAWr0ihxiOIA4OJiB5SpXCj0Wiwb98+XLp0CUOHDoWTkxNu3LgBZ2dnODry+j5RlWXdAP5aJ4Wa1FO6dhtHoNmLUqDx7QFY8d8lRETlMfhvyKtXr+K5555DYmIi8vLy0KtXLzg5OeGzzz5Dbm4uli1bZoo6iSxXXrq04nb890DiXgBCardSAo36FA8M7gfY2MtaJhFRTWFwuBk3bhyCg4Pxxx9/oF69etr2gQMHYvTo0UYtjshiafKAhJ3AX1HApe1AYZ5um1cXKdAEvAzYu8lXIxFRDWVwuDl06BAOHz4MlUp/IT0/Pz9cv37daIURWRxRBFw7KF1yurARyL2r21Y3EGj5qjSWxsVfvhqJiCyAweGmqKgIhYWFpdqvXbsGJycnoxRFZFFundXNGJyZpGt39AKaFw8Mdm/HgcFEREZicLjp1asX5s+fj6+++goAoFAokJWVhenTp6Nv375GL5CoRspIksJMfBSQdlbXrnIGAgZJgca7G2BlLV+NREQWSiGEEIa84MaNG+jevTusra1x4cIFBAcH48KFC3Bzc8OBAwfg7v54Tx6WkZEBFxcXpKenw9nZWe5yyJLk3gXOb5QCzbX9unZrFeDfVwo0jf8PUNrKVyMRUQ1lyPe3wT03Xl5eOH36NNavX4/Y2FgUFRVh1KhRCA8Ph52dXZWLJqqRNLnA5Z+kQJOwAyjM123z7lY8MHgQYFtHvhqJiGoZg3tuDhw4gM6dO0Op1M9FGo0GR44cwdNPP23UAo2NPTdUbUWFUs9M3PfAhU1AfoZum1trILB4YLCzj3w1EhFZGJP23HTv3h3JycmlLj+lp6eje/fuZQ42JqrxhABSTxcvgbBOmmyvhJOPtPxBYDhQv7VsJRIRkcTgcCOEgKKMuzpu374NBwcHoxRF9NhIv6IbGHw7TteudgWaD5YCTcN/AAoruSokIqKHVDrcvPjiiwCku6OGDx8OtVqt3VZYWIgzZ86gc+fOxq+QyNxybksLVMZHATcO69qt1dJMwS3CAf8+gFJd/jGIiEg2lQ43Li4uAKSeGycnJ73BwyqVCp06dcKYMWOMXyGRORRkSzMFx38PXNkFFGmKNygA3+7SOJpmLwJqF1nLJCKiR6t0uFm1ahUAoFGjRpg4cSIvQVHNV6QBEn8rnjF4M1CQpdvm3l665NR8CODUUL4aiYjIYAbfLVXT8W6pWk4I4OaJ4hmD1wPZN3XbnBtJgSYwHKgXKFuJRERUmknvlgKAjRs3YsOGDUhMTER+fr7etpMnT1blkESmde+SFGjio4C753XttvV0A4O9OnMJBCIiC2DwLR4LFy7EiBEj4O7ujlOnTuGpp55CvXr1cPnyZfTp08cUNRJVTXYqcPJLYG0nYGVT4Mh0Kdgo7aTLTQO2AxE3gJ5LgIZdGGyIiCyEwT03S5YswVdffYVXXnkF3377LSZNmoTGjRtj2rRpuHPnjilqJKq8gvvAxa1SD82VPYAonndJYQX49pR6aJoNBFRc5JWIyFIZHG4SExO1t3zb2dkhMzMTAPDaa6+hU6dOWLRokXErJHqUwgLgaowUaC5uBTTZum0NniweGBwGODSQrUQiIjIfg8NNgwYNcPv2bfj5+cHPzw//+9//0LZtWyQkJKCWjU0mOQkBJP9ePGNwNJBzS7fNtUnxEghDgboB8tVIRESyMDjc9OjRA9u3b0eHDh0watQoTJgwARs3bsSJEye0E/0Rmcydv4vvdForDRIuYVcfaDFE6qVp8BTHzxAR1WIG3wpeVFSEoqIi7cKZGzZswKFDh9C0aVNERERApVKZpFBj4a3gNdD9FOm27fjvgZuxunYbB6DpACnQ+PYErG1kK5GIiEzLkO9vo85zc/36dTRs+HhPeMZwU0PkZQAXt0i9NIm/AqJIaldYA416S4Gm6QtSwCEiIotnyPe3UVb7S0lJwbvvvoumTZsa/NolS5bA398ftra2CAoKwsGDByvcPy8vD1OnToWfnx/UajWaNGmCb775pqql0+OkMF9aAmF7GLDMA9g1XBooLIoAz05Aj0VARDLw4s9A4FAGGyIiKlOlx9zcu3cPb7/9Nvbs2QMbGxtMnjwZ77zzDmbMmIEvvvgCTzzxhMEhIzo6GuPHj8eSJUvQpUsXLF++HH369EFcXBx8fX3LfM3gwYNx8+ZNrFy5Ek2bNkVqaio0Gk2Z+1INIIqA60eAv6KkxSpzH5hOoE7z4hmDh0qDhImIiCqh0pelxo4di+3btyMsLAy7du1CfHw8evfujdzcXEyfPh3dunUz+M07duyIDh06YOnSpdq2wMBADBgwALNnzy61/65duzBkyBBcvnwZdevWNfj9AF6WemykndMNDM64qmt3aAC0eEUKNe4dODCYiIgAmGj5hZ9//hmrVq1Cz549MXbsWDRt2hQBAQGYP39+lYrMz89HbGwsJk+erNceGhqKI0eOlPmabdu2ITg4GJ999hm+++47ODg4oH///vjoo4/0Vil/UF5eHvLy8rTPMzIyqlQvGUHmdeCvdVKouXVa165yklbcbhEO+PYArKxlK5GIiGq+SoebGzduoGXLlgCAxo0bw9bWFqNHj67yG6elpaGwsBAeHh567R4eHkhJSSnzNZcvX8ahQ4dga2uLLVu2IC0tDWPHjsWdO3fKvSQ2e/ZszJw5s8p1UjXlpQPnN0l3OiXtA1DcUWhlA/j3kXpoGvcDbMoOp0RERIaqdLgpKiqCjY3uVltra2s4OFR/QKfiocsOQohSbQ/WoFAoEBUVBRcXFwDA3LlzMWjQICxevLjM3pspU6YgMjJS+zwjIwM+Pj7VrpsqoMkDEnZIPTSXfwIKdT1naPgPKdAEvAzY1ZOvRiIisliVDjdCCAwfPhxqtRoAkJubi4iIiFIBZ/PmzZU6npubG6ytrUv10qSmppbqzSnh6emJhg0baoMNII3REULg2rVraNasWanXqNVqbc1kQqIIuHZACjTnNwJ593Tb6j0hBZoWrwAujeSqkIiIaolKh5thw4bpPX/11Ver9cYqlQpBQUGIiYnBwIEDte0xMTF44YUXynxNly5d8MMPPyArKwuOjo4AgPPnz8PKygre3t7Vqoeq6NaZ4oHB64DMJF27Y8PigcGvAvXbcGAwERGZjVEn8TNUdHQ0XnvtNSxbtgwhISH46quv8PXXX+PcuXPw8/PDlClTcP36daxZswYAkJWVhcDAQHTq1AkzZ85EWloaRo8ejW7duuHrr7+u1HvybikjyEgE4tdKt2+n/alrV7sAzQZJvTTeT3NgMBERGY1J7pYyhbCwMNy+fRsffvghkpOT0apVK+zYsQN+fn4AgOTkZCQmJmr3d3R0RExMDN59910EBwejXr16GDx4MD7++GO5PkLtkXMHuLARiPseuP7ARIvWKsD/+eKBwc8DSlv5aiQiIoLMPTdyYM+NAQpypAHB8VHSAOGiguINCsCnm3TrdsBLgG0dWcskIiLLV2N6bugxVFQo3bIdHwVc2ATkPzAvUP020hia5kMAZ95xRkREjyeGGwKEAFJPSYHm7/VA1g3dNidfafmDwHDArZV8NRIREVUSw01tlp4gDQyO/x6485eu3bYOEDBYCjQNuwAKo6yvSkREZBZVCjffffcdli1bhoSEBBw9ehR+fn6YP38+/P39y72Nmx4T2WnA+Q1SL82NB5a5UNpKMwUHhkszB1ur5KuRiIioGgz+J/nSpUsRGRmJvn374t69eygsLAQAuLq6VnmdKTKxgmwgfh2w5f+A5Z7Ar29LwUZhBfj2BHqvAiJuAv02AE1fYLAhIqIazeCemy+//BJff/01BgwYgE8//VTbHhwcjIkTJxq1OKqGIg2Q+GvxwOAtQEGWbpt7h+IZg4cAjl7y1UhERGQCBoebhIQEtG/fvlS7Wq3G/fv3jVIUVZEQQMrx4oHB0UD2Td02F//iQBMO1GshX41EREQmZnC48ff3x+nTp7UT7ZXYuXOndtVwMrO7F4uXQIgC7l7QtdvWA5qHSaHGK4RLIBARUa1gcLh5//338fbbbyM3NxdCCBw7dgzr1q3D7NmzsWLFClPUSGW5f1PqnYmPAlKO6dqVdkDTAVKg8QsFrG3KPQQREZElMjjcjBgxAhqNBpMmTUJ2djaGDh2Khg0bYsGCBRgyZIgpaqQS+VnAxa1SoLkaAwhpMDcUVoBfL2mCvaYDAJWjnFUSERHJqlrLL6SlpaGoqAju7u7GrMmkauTyC8nHgJPzgYs/AppsXXuDp6QemuZhgIOHbOURERGZmkmXX5g5cyZeffVVNGnSBG5ublUukipJCGBzXyD3tvTctanUQxM4FKjTTN7aiIiIHkMGz3OzadMmBAQEoFOnTli0aBFu3bplirqoRM5tXbB55Sgw8jzQeTqDDRERUTkMDjdnzpzBmTNn0KNHD8ydOxcNGzZE3759sXbtWmRnZz/6AGSYzKvSfx0aAF6deMcTERHRI1Rp0aAnnngCs2bNwuXLl7F37174+/tj/PjxaNCggbHro4zicOPsV/F+REREBKCK4eZBDg4OsLOzg0qlQkFBgTFqogeVhBsnhhsiIqLKqFK4SUhIwCeffIKWLVsiODgYJ0+exIwZM5CSkmLs+og9N0RERAYx+G6pkJAQHDt2DK1bt8aIESO089yQiWjDja+8dRAREdUQBoeb7t27Y8WKFXjiiSdMUQ89jD03REREBjE43MyaNcsUdVB5GG6IiIgMUqlwExkZiY8++ggODg6IjIyscN+5c+capTCCtNxC7h3pZ4YbIiKiSqlUuDl16pT2TqhTp06ZtCB6QEmvjdpFehAREdEjVSrc7N27t8yfycQyE6X/steGiIio0gy+FXzkyJHIzMws1X7//n2MHDnSKEVRMc5xQ0REZDCDw823336LnJycUu05OTlYs2aNUYqiYhxMTEREZLBK3y2VkZEBIQSEEMjMzIStra12W2FhIXbs2AF3d3eTFFlrMdwQEREZrNLhxtXVFQqFAgqFAgEBAaW2KxQKzJw506jF1XoMN0RERAardLjZu3cvhBDo0aMHNm3ahLp162q3qVQq+Pn5wcvLyyRF1loMN0RERAardLjp1q0bAGldKV9fXygUCpMVRQAK84GsG9LPXHqBiIio0ioVbs6cOYNWrVrBysoK6enpOHv2bLn7tmnTxmjF1WqZ1wAIwFoN2HMsExERUWVVKty0a9cOKSkpcHd3R7t27aBQKCCEKLWfQqFAYWGh0YuslR5cMFNRpcXbiYiIaqVKhZuEhATUr19f+zOZAee4ISIiqpJKhRs/P78yfyYT4mBiIiKiKqnSJH4///yz9vmkSZPg6uqKzp074+rVq0Ytrlbj0gtERERVYnC4mTVrFuzs7AAAR48exaJFi/DZZ5/Bzc0NEyZMMHqBtRZ7boiIiKqk0reCl0hKSkLTpk0BAFu3bsWgQYPwxhtvoEuXLnjmmWeMXV/txXBDRERUJQb33Dg6OuL27dsAgD179qBnz54AAFtb2zLXnKIqEEW8LEVERFRFBvfc9OrVC6NHj0b79u1x/vx5PP/88wCAc+fOoVGjRsaur3a6f1OaxE9hBTg2lLsaIiKiGsXgnpvFixcjJCQEt27dwqZNm1CvXj0AQGxsLF555RWjF1grlVyScmwIWNvIWwsREVENY3DPjaurKxYtWlSqnYtmGpF2jhsuu0BERGQog8MNANy7dw8rV65EfHw8FAoFAgMDMWrUKLi4uBi7vtqJg4mJiIiqzODLUidOnECTJk0wb9483LlzB2lpaZg3bx6aNGmCkydPmqLG2ofhhoiIqMoM7rmZMGEC+vfvj6+//hpKpfRyjUaD0aNHY/z48Thw4IDRi6x1MhluiIiIqsrgcHPixAm9YAMASqUSkyZNQnBwsFGLq7XYc0NERFRlBl+WcnZ2RmJiYqn2pKQkODk5GaWoWi+Dc9wQERFVlcHhJiwsDKNGjUJ0dDSSkpJw7do1rF+/HqNHj+at4MaQew/Iz5B+dubdUkRERIYy+LLUF198AYVCgddffx0ajQYAYGNjg7feeguffvqp0QusdUouSdm5ATYO8tZCRERUAxkcblQqFRYsWIDZs2fj0qVLEEKgadOmsLe3N0V9tQ/H2xAREVVLpS9LZWdn4+2330bDhg3h7u6O0aNHw9PTE23atGGwMSaGGyIiomqpdLiZPn06Vq9ejeeffx5DhgxBTEwM3nrrLVPWVjsx3BAREVVLpS9Lbd68GStXrsSQIUMAAK+++iq6dOmCwsJCWFtbm6zAWieTSy8QERFVR6V7bpKSktC1a1ft86eeegpKpRI3btwwSWG1FntuiIiIqqXS4aawsBAqlUqvTalUau+YIiNhuCEiIqqWSl+WEkJg+PDhUKvV2rbc3FxERETAwUF3y/LmzZuNW2FtUpADZKdKPzPcEBERVUmlw82wYcNKtb366qtGLabWyyyemdjGAbCtK28tRERENVSlw82qVatMWQcB+ssuKBTy1kJERFRDGbz8grEtWbIE/v7+sLW1RVBQEA4ePFip1x0+fBhKpRLt2rUzbYHmxPE2RERE1SZruImOjsb48eMxdepUnDp1Cl27dkWfPn3KXJjzQenp6Xj99dfx7LPPmqlSM8lkuCEiIqouWcPN3LlzMWrUKIwePRqBgYGYP38+fHx8sHTp0gpf9+abb2Lo0KEICQkxU6VmUtJz48RwQ0REVFWyhZv8/HzExsYiNDRUrz00NBRHjhwp93WrVq3CpUuXMH36dFOXaH68LEVERFRtBi+caSxpaWkoLCyEh4eHXruHhwdSUlLKfM2FCxcwefJkHDx4EEpl5UrPy8tDXl6e9nlGRkbVizY1bbjh7MRERERVVaWem++++w5dunSBl5cXrl6VvpDnz5+PH3/80eBjKR66K0gIUaoNkCYRHDp0KGbOnImAgIBKH3/27NlwcXHRPnx8fAyu0SyKNEDmNeln9twQERFVmcHhZunSpYiMjETfvn1x7949FBYWAgBcXV0xf/78Sh/Hzc0N1tbWpXppUlNTS/XmAEBmZiZOnDiBd955B0qlEkqlEh9++CH++OMPKJVK/Pbbb2W+z5QpU5Cenq59JCUlVf7DmlPWDUAUAlZKwMFT7mqIiIhqLIPDzZdffomvv/4aU6dO1VswMzg4GGfPnq30cVQqFYKCghATE6PXHhMTg86dO5fa39nZGWfPnsXp06e1j4iICDRv3hynT59Gx44dy3wftVoNZ2dnvcdjSTuY2Aew4kKkREREVWXwmJuEhAS0b9++VLtarcb9+/cNOlZkZCRee+01BAcHIyQkBF999RUSExMREREBQOp1uX79OtasWQMrKyu0atVK7/Xu7u6wtbUt1V4jcTAxERGRURgcbvz9/XH69Gn4+el/Ce/cuRMtW7Y06FhhYWG4ffs2PvzwQyQnJ6NVq1bYsWOH9tjJycmPnPPGYjDcEBERGYXB4eb999/H22+/jdzcXAghcOzYMaxbtw6zZ8/GihUrDC5g7NixGDt2bJnbVq9eXeFrZ8yYgRkzZhj8no+lknWlOMcNERFRtRgcbkaMGAGNRoNJkyYhOzsbQ4cORcOGDbFgwQIMGTLEFDXWDuy5ISIiMooqzXMzZswYjBkzBmlpaSgqKoK7u7ux66p9GG6IiIiMolqT+Lm5uRmrjtpNCIYbIiIiI6nSgOKyJtkrcfny5WoVVCvlpAGaHOlnp8d0kkEiIqIawuBwM378eL3nBQUFOHXqFHbt2oX333/fWHXVLiW9Ng4NAKVa3lqIiIhqOIPDzbhx48psX7x4MU6cOFHtgmolXpIiIiIyGqOtCt6nTx9s2rTJWIerXbSzEzPcEBERVZfRws3GjRtRt25dYx2udmHPDRERkdEYfFmqffv2egOKhRBISUnBrVu3sGTJEqMWV2sw3BARERmNweFmwIABes+trKxQv359PPPMM2jRooWx6qpdGG6IiIiMxqBwo9Fo0KhRI/Tu3RsNGjQwVU21T8nSCww3RERE1WbQmBulUom33noLeXl5pqqn9snPAnLvSD8z3BAREVWbwQOKO3bsiFOnTpmiltqp5JKU2hVQO8taChERkSUweMzN2LFj8c9//hPXrl1DUFAQHBwc9La3adPGaMXVChxvQ0REZFSVDjcjR47E/PnzERYWBgB47733tNsUCgWEEFAoFCgsLDR+lZaM4YaIiMioKh1uvv32W3z66adISEgwZT21j3YCP1956yAiIrIQlQ43QggAgJ8fexiMij03RERERmXQgOKKVgOnKmK4ISIiMiqDBhQHBAQ8MuDcuXOnWgXVOpkMN0RERMZkULiZOXMmXFxcTFVL7VOYD2QlSz8z3BARERmFQeFmyJAhcHd3N1UttU9mEgABKG0Be55XIiIiY6j0mBuOtzGBjOJlF5x8AZ5fIiIio6h0uCm5W4qMiIOJiYiIjK7Sl6WKiopMWUftxHBDRERkdAavLUVGxHBDRERkdAw3cuJt4EREREbHcCMnLr1ARERkdAw3chFFxbeCgz03RERERsRwI5f7KdIkfgorwLGh3NUQERFZDIYbuZRcknJsCFjbyFsLERGRBWG4kQvvlCIiIjIJhhu5MNwQERGZBMONXEqWXmC4ISIiMiqGG7lwjhsiIiKTYLiRCy9LERERmQTDjRyEeGACP4YbIiIiY2K4kUPePSA/U/rZmbMTExERGRPDjRxKem3s3AAbe3lrISIisjAMN3LgeBsiIiKTYbiRA8MNERGRyTDcyIHhhoiIyGQYbuTAcENERGQyDDdy4G3gREREJsNwI4dMLr1ARERkKgw35laQA2SnSj8z3BARERkdw425lfTa2DgCtnXkrYWIiMgCMdyY24ODiRUKeWshIiKyQAw35sY7pYiIiEyK4cbctOGGa0oRERGZAsONufE2cCIiIpNiuDE3XpYiIiIyKYYbc2O4ISIiMimGG3Mq0gBZ16WfGW6IiIhMguHGnLKuA6IQsLIBHD3lroaIiMgiMdyYU0bxBH5OPoCCp56IiMgU+A1rThxvQ0REZHKyh5slS5bA398ftra2CAoKwsGDB8vdd/PmzejVqxfq168PZ2dnhISEYPfu3WastpoYboiIiExO1nATHR2N8ePHY+rUqTh16hS6du2KPn36IDExscz9Dxw4gF69emHHjh2IjY1F9+7d0a9fP5w6dcrMlVcRww0REZHJKYQQQq4379ixIzp06IClS5dq2wIDAzFgwADMnj27Usd44oknEBYWhmnTplVq/4yMDLi4uCA9PR3Ozs5VqrvKNvYGru4Ben8DtBph3vcmIiKqwQz5/pat5yY/Px+xsbEIDQ3Vaw8NDcWRI0cqdYyioiJkZmaibt26pijR+LSzE3PpBSIiIlNRyvXGaWlpKCwshIeHh167h4cHUlJSKnWMOXPm4P79+xg8eHC5++Tl5SEvL0/7PCMjo2oFV5cQQGbx5TZeliIiIjIZ2QcUKxQKvedCiFJtZVm3bh1mzJiB6OhouLu7l7vf7Nmz4eLion34+PhUu+YqybkFaHKkn51kqoGIiKgWkC3cuLm5wdraulQvTWpqaqnenIdFR0dj1KhR2LBhA3r27FnhvlOmTEF6err2kZSUVO3aq6TkkpSDJ6BUy1MDERFRLSBbuFGpVAgKCkJMTIxee0xMDDp37lzu69atW4fhw4dj7dq1eP755x/5Pmq1Gs7OznoPWfBOKSIiIrOQbcwNAERGRuK1115DcHAwQkJC8NVXXyExMREREREApF6X69evY82aNQCkYPP6669jwYIF6NSpk7bXx87ODi4uLrJ9jkphuCEiIjILWcNNWFgYbt++jQ8//BDJyclo1aoVduzYAT8/KQAkJyfrzXmzfPlyaDQavP3223j77be17cOGDcPq1avNXb5hMjiYmIiIyBxknedGDrLNc7N1AHDpR+DZxUC7seZ7XyIiIgtQI+a5qXV4WYqIiMgsGG7MJZPhhoiIyBwYbswhPxPIvSv9zNmJiYiITIrhxhxKLkmpXQG1TLeiExER1RIMN+bA8TZERERmw3BjDgw3REREZsNwYw4MN0RERGbDcGMODDdERERmw3BjDgw3REREZsNwYw6ZXHqBiIjIXBhuTK0wH8hKln5muCEiIjI5hhtTy0wCIAClHWBXX+5qiIiILB7DjamVjLdx8gUUCnlrISIiqgUYbkxNO5iYyy4QERGZA8ONqfFOKSIiIrNiuDE1hhsiIiKzYrgxNYYbIiIis2K4MTWGGyIiIrNiuDElUVR8KzgYboiIiMyE4caUspKBogJAYQ04NpS7GiIiolqB4caUSpZdcGwIWCnlrYWIiKiWYLgxJY63ISIiMjuGG1NiuCEiIjI7hhtTYrghIiIyO4YbU+LSC0RERGbHcGNK7LkhIiIyO4YbUxHigRXBGW6IiIjMheHGVHLvAgVZ0s+8LEVERGQ2DDemUtJrY1cfsLGXtxYiIqJahOHGVDjehoiISBYMN6aSyXBDREQkB4YbU8koXnqB4YaIiMisGG5MhZeliIiIZMFwYyoMN0RERLJguDEVhhsiIiJZMNyYQkE2kHNL+tmJc9wQERGZE8ONKZQMJrZxBGzryFsLERFRLcNwYwoP3gauUMhbCxERUS3DcGMKHG9DREQkG4YbU2C4ISIikg3DjSkw3BAREcmG4cYUGG6IiIhkw3BjClx6gYiISDYMN8ZWpAGyrks/M9wQERGZHcONsWVdB0QhYK0CHBrIXQ0REVGto5S7AItTMt7GyQdQMDsSWQIhBDQaDQoLC+Uuhcii2djYwNrautrHYbgxNm244bILRJYgPz8fycnJyM7OlrsUIounUCjg7e0NR0fHah2H4cbYeKcUkcUoKipCQkICrK2t4eXlBZVKBQVnHScyCSEEbt26hWvXrqFZs2bV6sFhuDE2hhsii5Gfn4+ioiL4+PjA3t5e7nKILF79+vVx5coVFBQUVCvccFCIsTHcEFkcKyv+VUlkDsbqGeX/scbGcENERCQrhhtjEgLI5AR+REREcmK4MabsVECTC0Ah3QpOREQ1yu3bt+Hu7o4rV67IXYrFWbRoEfr372+W92K4MaaSXhtHT2kSPyIiGQwfPhwKhQIKhQJKpRK+vr546623cPfu3VL7HjlyBH379kWdOnVga2uL1q1bY86cOWXO6bN371707dsX9erVg729PVq2bIl//vOfuH79ujk+llnMnj0b/fr1Q6NGjeQuxWT279+PoKAg2NraonHjxli2bFmF+69evVr75+nhR2pqKgDgypUrZW7ftWuX9jhjxozB8ePHcejQIZN+PoDhxri0c9zwkhQRyeu5555DcnIyrly5ghUrVmD79u0YO3as3j5btmxBt27d4O3tjb179+Kvv/7CuHHj8Mknn2DIkCEQQmj3Xb58OXr27IkGDRpg06ZNiIuLw7Jly5Ceno45c+aY7XPl5+eb7Ng5OTlYuXIlRo8eXa3jmLLG6kpISEDfvn3RtWtXnDp1Cv/+97/x3nvvYdOmTeW+JiwsDMnJyXqP3r17o1u3bnB3d9fb95dfftHbr0ePHtptarUaQ4cOxZdffmmyz6clapn09HQBQKSnpxv/4Me/EOILCLF9iPGPTURml5OTI+Li4kROTo7UUFQkRH6WPI+iokrXPWzYMPHCCy/otUVGRoq6detqn2dlZYl69eqJF198sdTrt23bJgCI9evXCyGESEpKEiqVSowfP77M97t79265tdy9e1eMGTNGuLu7C7VaLZ544gmxfft2IYQQ06dPF23bttXbf968ecLPz6/UZ5k1a5bw9PQUfn5+YvLkyaJjx46l3qt169Zi2rRp2ufffPONaNGihVCr1aJ58+Zi8eLF5dYphBCbNm0Sbm5uem0ajUaMHDlSNGrUSNja2oqAgAAxf/58vX3KqlEIIa5duyYGDx4sXF1dRd26dUX//v1FQkKC9nXHjh0TPXv2FPXq1RPOzs7i6aefFrGxsRXWWF2TJk0SLVq00Gt78803RadOnSp9jNTUVGFjYyPWrFmjbUtISBAAxKlTpyp87b59+4RKpRLZ2dllbi/1/9wDDPn+5jw3xsQ7pYgsmyYbWFi9mVOr7L0swMahSi+9fPkydu3aBRsbG23bnj17cPv2bUycOLHU/v369UNAQADWrVuHsLAw/PDDD8jPz8ekSZPKPL6rq2uZ7UVFRejTpw8yMzPx/fffo0mTJoiLizN4/pJff/0Vzs7OiImJ0fYmffrpp7h06RKaNGkCADh37hzOnj2LjRs3AgC+/vprTJ8+HYsWLUL79u1x6tQpjBkzBg4ODhg2bFiZ73PgwAEEBweX+gze3t7YsGED3NzccOTIEbzxxhvw9PTE4MGDy60xOzsb3bt3R9euXXHgwAEolUp8/PHHeO6553DmzBmoVCpkZmZi2LBhWLhwIQBgzpw56Nu3Ly5cuAAnJ6cya4yKisKbb75Z4flavnw5wsPDy9x29OhRhIaG6rX17t0bK1euREFBgd6fkfKsWbMG9vb2GDRoUKlt/fv3R25uLpo1a4YJEyaU2ic4OBgFBQU4duwYunXr9sj3qirZw82SJUvw+eefIzk5GU888QTmz5+Prl27lrv//v37ERkZiXPnzsHLywuTJk1CRESEGSuugDbccOkFIpLXTz/9BEdHRxQWFiI3NxcAMHfuXO328+fPAwACAwPLfH2LFi20+1y4cAHOzs7w9PQ0qIZffvkFx44dQ3x8PAICAgAAjRs3NvizODg4YMWKFVCpdGMZ27Rpg7Vr1+KDDz4AIH3pP/nkk9r3+eijjzBnzhy8+OKLAAB/f3/ExcVh+fLl5YabK1euwMvLS6/NxsYGM2fO1D739/fHkSNHsGHDBr1w83CN33zzDaysrLBixQrt3C2rVq2Cq6sr9u3bh9DQUL1LNoAUSurUqYP9+/fj//7v/8qssX///ujYsWOF58vDw6PcbSkpKaW2e3h4QKPRIC0trVK/42+++QZDhw6FnZ2dts3R0RFz585Fly5dYGVlhW3btiEsLAzffvstXn31Ve1+Dg4OcHV1xZUrVyw33ERHR2P8+PFYsmQJunTpguXLl6NPnz6Ii4uDr2/pgFByrXDMmDH4/vvvcfjwYYwdOxb169fHSy+9JMMneAh7bogsm9Je6kGR670N0L17dyxduhTZ2dlYsWIFzp8/j3fffbfUfuKBcTUPt5d8KT/4syFOnz4Nb29vbeCoqtatW+sFGwAIDw/HN998gw8++ABCCKxbtw7jx48HANy6dQtJSUkYNWoUxowZo32NRqOBi4tLue+Tk5MDW1vbUu3Lli3DihUrcPXqVeTk5CA/Px/t2rWrsMbY2FhcvHixVA9Mbm4uLl26BABITU3FtGnT8Ntvv+HmzZsoLCxEdnY2EhMTy63Rycmp3F6dynr4d1nyZ6Ayv+OjR48iLi4Oa9as0Wt3c3PDhAkTtM+Dg4Nx9+5dfPbZZ3rhBgDs7OxMvlabrOFm7ty5GDVqlHbw1vz587F7924sXboUs2fPLrX/smXL4Ovri/nz5wOQ/sVx4sQJfPHFFww3RGR6CkWVLw2Zm4ODA5o2bQoAWLhwIbp3746ZM2fio48+AgBt4IiPj0fnzp1Lvf6vv/5Cy5Yttfump6cjOTnZoN6bB/9lXxYrK6tS4aqgoKDMz/KwoUOHYvLkyTh58iRycnKQlJSEIUOGAJAuJQHSpamHezkquiTm5uZW6o6yDRs2YMKECZgzZw5CQkLg5OSEzz//HL///nuFNRYVFSEoKAhRUVGl3qd+/foApLvabt26hfnz58PPzw9qtRohISEVDkiu7mWpBg0aICUlRa8tNTUVSqUS9erVq/C4ALBixQq0a9cOQUFBj9y3U6dOWLFiRan2O3fuaM+BqcgWbvLz8xEbG4vJkyfrtYeGhuLIkSNlvqYq1wrz8vKQl5enfZ6RkWGE6suQlwHk3ZN+ZrghosfM9OnT0adPH7z11lvw8vJCaGgo6tatizlz5pQKN9u2bcOFCxe0QWjQoEGYPHkyPvvsM8ybN6/Use/du1fmuJs2bdrg2rVrOH/+fJm9N/Xr10dKSopez9Dp06cr9Xm8vb3x9NNPIyoqCjk5OejZs6f2couHhwcaNmyIy5cvl/slX5b27dvj+++/12s7ePAgOnfurHenWUnPS0U6dOiA6OhouLu7w9nZucx9Dh48iCVLlqBv374AgKSkJKSlpVV43OpelgoJCcH27dv12vbs2YPg4OBHjrfJysrChg0byux8KMupU6dKheFLly4hNzcX7du3r9Qxqkq2W8HT0tJQWFhY5rW/h1NliUddKyzL7Nmz4eLion34+Jhocr3sVMDODbCtC6iq12VIRGRszzzzDJ544gnMmjULgNTTsHz5cvz444944403cObMGVy5cgUrV67E8OHDMWjQIO2YEh8fH8ybNw8LFizAqFGjsH//fly9ehWHDx/Gm2++qQ1BD+vWrRuefvppvPTSS4iJiUFCQgJ27typnfvkmWeewa1bt/DZZ5/h0qVLWLx4MXbu3FnpzxQeHo7169fjhx9+KHXpY8aMGZg9ezYWLFiA8+fP4+zZs1i1apXeuKOH9e7dG+fOndPrvWnatClOnDiB3bt34/z58/jggw9w/PjxStXm5uaGF154AQcPHkRCQgL279+PcePG4dq1a9pjf/fdd4iPj8fvv/+O8PDwR/Z2OTk5oWnTphU+KrpsFRERgatXryIyMhLx8fH45ptvsHLlSr2B5Vu2bEGLFi1KvTY6OhoajabMwPjtt99i7dq1iI+Px99//40vvvgCCxcuLHUp9ODBg2jcuLF2ILjJPPJ+KhO5fv26ACCOHDmi1/7xxx+L5s2bl/maZs2aiVmzZum1HTp0SAAQycnJZb4mNzdXpKenax9JSUmmuxVcCCEKSt++RkQ1U0W3pT7OyroVXAghoqKihEqlEomJidq2AwcOiOeee064uLgIlUolWrZsKb744guh0WhKvT4mJkb07t1b1KlTR9ja2ooWLVqIiRMnihs3bpRby+3bt8WIESNEvXr1hK2trWjVqpX46aeftNuXLl0qfHx8hIODg3j99dfFJ598Uuat4GW5e/euUKvVwt7eXmRmZpb5edu1aydUKpWoU6eOePrpp8XmzZvLrVUIITp16iSWLVumfZ6bmyuGDx8uXFxchKurq3jrrbfE5MmT9W5hL6/G5ORk8frrrws3NzehVqtF48aNxZgxY7TfPydPnhTBwcFCrVaLZs2aiR9++EH4+fmJefPmVVhjde3bt0+0b99eqFQq0ahRI7F06VK97atWrRJlxYOQkBAxdOjQMo+5evVqERgYKOzt7YWTk5MICgoS3333Xan9QkNDxezZs8utzVi3giuEKGc0mYnl5+fD3t4eP/zwAwYOHKhtHzduHE6fPo39+/eXes3TTz+N9u3bY8GCBdq2LVu2YPDgwcjOzq7ULWwZGRlwcXFBenp6uV2FRESANPgzISEB/v7+ZQ40JcuzY8cOTJw4EX/++SdXgzeyP//8E88++yzOnz9f7sDuiv6fM+T7W7bfnEqlQlBQEGJiYvTaY2JiyhzcBkjXCh/ev7LXComIiB6lb9++ePPNNy1qSYnHxY0bN7BmzZoK71gzFlnvloqMjMRrr72G4OBghISE4KuvvkJiYqJ23popU6bg+vXr2lvOIiIisGjRIkRGRmLMmDE4evQoVq5ciXXr1sn5MYiIyIKMGzdO7hIs0sM3BJmSrOEmLCwMt2/fxocffojk5GS0atUKO3bsgJ+fdLdRcnKy3v3+/v7+2LFjByZMmIDFixfDy8sLCxcufDxuAyciIqLHgmxjbuTCMTdEVFkcc0NkXjV+zA0RUU1Ry/4NSCQbY/2/xnBDRFSOkhsVTD1VPBFJSmZnNnRx1YfJvnAmEdHjytraGq6urkhNTQUA2NvbV2mNJSJ6tKKiIty6dQv29vZQKqsXTxhuiIgq0KBBAwDQBhwiMh0rKyv4+vpW+x8RDDdERBVQKBTw9PSEu7t7mYs6EpHxqFQqo0yeyHBDRFQJ1tbW1R4HQETmwQHFREREZFEYboiIiMiiMNwQERGRRal1Y25KJgjKyMiQuRIiIiKqrJLv7cpM9Ffrwk1mZiYAwMfHR+ZKiIiIyFCZmZmPXFm81q0tVVRUhBs3bsDJycnok3FlZGTAx8cHSUlJXLfKhHiezYPn2Tx4ns2H59o8THWehRDIzMyEl5fXI28Xr3U9N1ZWVvD29jbpezg7O/N/HDPgeTYPnmfz4Hk2H55r8zDFeX5Uj00JDigmIiIii8JwQ0RERBaF4caI1Go1pk+fDrVaLXcpFo3n2Tx4ns2D59l8eK7N43E4z7VuQDERERFZNvbcEBERkUVhuCEiIiKLwnBDREREFoXhhoiIiCwKw42BlixZAn9/f9ja2iIoKAgHDx6scP/9+/cjKCgItra2aNy4MZYtW2amSms2Q87z5s2b0atXL9SvXx/Ozs4ICQnB7t27zVhtzWXon+cShw8fhlKpRLt27UxboIUw9Dzn5eVh6tSp8PPzg1qtRpMmTfDNN9+Yqdqay9DzHBUVhbZt28Le3h6enp4YMWIEbt++baZqa6YDBw6gX79+8PLygkKhwNatWx/5Glm+BwVV2vr164WNjY34+uuvRVxcnBg3bpxwcHAQV69eLXP/y5cvC3t7ezFu3DgRFxcnvv76a2FjYyM2btxo5sprFkPP87hx48R///tfcezYMXH+/HkxZcoUYWNjI06ePGnmymsWQ89ziXv37onGjRuL0NBQ0bZtW/MUW4NV5Tz3799fdOzYUcTExIiEhATx+++/i8OHD5ux6prH0PN88OBBYWVlJRYsWCAuX74sDh48KJ544gkxYMAAM1des+zYsUNMnTpVbNq0SQAQW7ZsqXB/ub4HGW4M8NRTT4mIiAi9thYtWojJkyeXuf+kSZNEixYt9NrefPNN0alTJ5PVaAkMPc9ladmypZg5c6axS7MoVT3PYWFh4j//+Y+YPn06w00lGHqed+7cKVxcXMTt27fNUZ7FMPQ8f/7556Jx48Z6bQsXLhTe3t4mq9HSVCbcyPU9yMtSlZSfn4/Y2FiEhobqtYeGhuLIkSNlvubo0aOl9u/duzdOnDiBgoICk9Vak1XlPD+sqKgImZmZqFu3rilKtAhVPc+rVq3CpUuXMH36dFOXaBGqcp63bduG4OBgfPbZZ2jYsCECAgIwceJE5OTkmKPkGqkq57lz5864du0aduzYASEEbt68iY0bN+L55583R8m1hlzfg7Vu4cyqSktLQ2FhITw8PPTaPTw8kJKSUuZrUlJSytxfo9EgLS0Nnp6eJqu3pqrKeX7YnDlzcP/+fQwePNgUJVqEqpznCxcuYPLkyTh48CCUSv7VURlVOc+XL1/GoUOHYGtriy1btiAtLQ1jx47FnTt3OO6mHFU5z507d0ZUVBTCwsKQm5sLjUaD/v3748svvzRHybWGXN+D7LkxkEKh0HsuhCjV9qj9y2onfYae5xLr1q3DjBkzEB0dDXd3d1OVZzEqe54LCwsxdOhQzJw5EwEBAeYqz2IY8ue5qKgICoUCUVFReOqpp9C3b1/MnTsXq1evZu/NIxhynuPi4vDee+9h2rRpiI2Nxa5du5CQkICIiAhzlFqryPE9yH9+VZKbmxusra1L/SsgNTW1VCot0aBBgzL3VyqVqFevnslqrcmqcp5LREdHY9SoUfjhhx/Qs2dPU5ZZ4xl6njMzM3HixAmcOnUK77zzDgDpS1gIAaVSiT179qBHjx5mqb0mqcqfZ09PTzRs2BAuLi7atsDAQAghcO3aNTRr1sykNddEVTnPs2fPRpcuXfD+++8DANq0aQMHBwd07doVH3/8MXvWjUSu70H23FSSSqVCUFAQYmJi9NpjYmLQuXPnMl8TEhJSav89e/YgODgYNjY2Jqu1JqvKeQakHpvhw4dj7dq1vGZeCYaeZ2dnZ5w9exanT5/WPiIiItC8eXOcPn0aHTt2NFfpNUpV/jx36dIFN27cQFZWlrbt/PnzsLKygre3t0nrramqcp6zs7NhZaX/FWhtbQ1A17NA1Sfb96BJhytbmJJbDVeuXCni4uLE+PHjhYODg7hy5YoQQojJkyeL1157Tbt/yS1wEyZMEHFxcWLlypW8FbwSDD3Pa9euFUqlUixevFgkJydrH/fu3ZPrI9QIhp7nh/Fuqcox9DxnZmYKb29vMWjQIHHu3Dmxf/9+0axZMzF69Gi5PkKNYOh5XrVqlVAqlWLJkiXi0qVL4tChQyI4OFg89dRTcn2EGiEzM1OcOnVKnDp1SgAQc+fOFadOndLecv+4fA8y3Bho8eLFws/PT6hUKtGhQwexf/9+7bZhw4aJbt266e2/b98+0b59e6FSqUSjRo3E0qVLzVxxzWTIee7WrZsAUOoxbNgw8xdewxj65/lBDDeVZ+h5jo+PFz179hR2dnbC29tbREZGiuzsbDNXXfMYep4XLlwoWrZsKezs7ISnp6cIDw8X165dM3PVNcvevXsr/Pv2cfkeVAjB/jciIiKyHBxzQ0RERBaF4YaIiIgsCsMNERERWRSGGyIiIrIoDDdERERkURhuiIiIyKIw3BAREZFFYbghIj2rV6+Gq6ur3GVUWaNGjTB//vwK95kxYwbatWtnlnqIyPwYbogs0PDhw6FQKEo9Ll68KHdpWL16tV5Nnp6eGDx4MBISEoxy/OPHj+ONN97QPlcoFNi6davePhMnTsSvv/5qlPcrz8Of08PDA/369cO5c+cMPk5NDptEcmC4IbJQzz33HJKTk/Ue/v7+cpcFQFqIMzk5GTdu3MDatWtx+vRp9O/fH4WFhdU+dv369WFvb1/hPo6OjiZdkbjEg5/z559/xv379/H8888jPz/f5O9NVJsx3BBZKLVajQYNGug9rK2tMXfuXLRu3RoODg7w8fHB2LFj9Vagftgff/yB7t27w8nJCc7OzggKCsKJEye0248cOYKnn34adnZ28PHxwXvvvYf79+9XWJtCoUCDBg3g6emJ7t27Y/r06fjzzz+1PUtLly5FkyZNoFKp0Lx5c3z33Xd6r58xYwZ8fX2hVqvh5eWF9957T7vtwctSjRo1AgAMHDgQCoVC+/zBy1K7d++Gra0t7t27p/ce7733Hrp162a0zxkcHIwJEybg6tWr+Pvvv7X7VPT72LdvH0aMGIH09HRtD9CMGTMAAPn5+Zg0aRIaNmwIBwcHdOzYEfv27auwHqLaguGGqJaxsrLCwoUL8eeff+Lbb7/Fb7/9hkmTJpW7f3h4OLy9vXH8+HHExsZi8uTJsLGxAQCcPXsWvXv3xosvvogzZ84gOjoahw4dwjvvvGNQTXZ2dgCAgoICbNmyBePGjcM///lP/Pnnn3jzzTcxYsQI7N27FwCwceNGzJs3D8uXL8eFCxewdetWtG7duszjHj9+HACwatUqJCcna58/qGfPnnB1dcWmTZu0bYWFhdiwYQPCw8ON9jnv3buHtWvXAoD2/AEV/z46d+6M+fPna3uAkpOTMXHiRADAiBEjcPjwYaxfvx5nzpzByy+/jOeeew4XLlyodE1EFsvkS3MSkdkNGzZMWFtbCwcHB+1j0KBBZe67YcMGUa9ePe3zVatWCRcXF+1zJycnsXr16jJf+9prr4k33nhDr+3gwYPCyspK5OTklPmah4+flJQkOnXqJLy9vUVeXp7o3LmzGDNmjN5rXn75ZdG3b18hhBBz5swRAQEBIj8/v8zj+/n5iXnz5mmfAxBbtmzR2+fhFc3fe+890aNHD+3z3bt3C5VKJe7cuVOtzwlAODg4CHt7e+3qyf379y9z/xKP+n0IIcTFixeFQqEQ169f12t/9tlnxZQpUyo8PlFtoJQ3WhGRqXTv3h1Lly7VPndwcAAA7N27F7NmzUJcXBwyMjKg0WiQm5uL+/fva/d5UGRkJEaPHo3vvvsOPXv2xMsvv4wmTZoAAGJjY3Hx4kVERUVp9xdCoKioCAkJCQgMDCyztvT0dDg6OkIIgezsbHTo0AGbN2+GSqVCfHy83oBgAOjSpQsWLFgAAHj55Zcxf/58NG7cGM899xz69u2Lfv36Qams+l9n4eHhCAkJwY0bN+Dl5YWoqCj07dsXderUqdbndHJywsmTJ6HRaLB//358/vnnWLZsmd4+hv4+AODkyZMQQiAgIECvPS8vzyxjiYgedww3RBbKwcEBTZs21Wu7evUq+vbti4iICHz00UeoW7cuDh06hFGjRqGgoKDM48yYMQNDhw7Fzz//jJ07d2L69OlYv349Bg4ciKKiIrz55pt6Y15K+Pr6lltbyZe+lZUVPDw8Sn2JKxQKvedCCG2bj48P/v77b8TExOCXX37B2LFj8fnnn2P//v16l3sM8dRTT6FJkyZYv3493nrrLWzZsgWrVq3Sbq/q57SystL+Dlq0aIGUlBSEhYXhwIEDAKr2+yipx9raGrGxsbC2ttbb5ujoaNBnJ7JEDDdEtciJEyeg0WgwZ84cWFlJQ+42bNjwyNcFBAQgICAAEyZMwCuvvIJVq1Zh4MCB6NChA86dO1cqRD3Kg1/6DwsMDMShQ4fw+uuva9uOHDmi1ztiZ2eH/v37o3///nj77bfRokULnD17Fh06dCh1PBsbm0rdhTV06FBERUXB29sbVlZWeP7557Xbqvo5HzZhwgTMnTsXW7ZswcCBAyv1+1CpVKXqb9++PQoLC5GamoquXbtWqyYiS8QBxUS1SJMmTaDRaPDll1/i8uXL+O6770pdJnlQTk4O3nnnHezbtw9Xr17F4cOHcfz4cW3Q+Ne//oWjR4/i7bffxunTp3HhwgVs27YN7777bpVrfP/997F69WosW7YMFy5cwNy5c7F582btQNrVq1dj5cqV+PPPP7Wfwc7ODn5+fmUer1GjRvj111+RkpKCu3fvlvu+4eHhOHnyJD755BMMGjQItra22m3G+pzOzs4YPXo0pk+fDiFEpX4fjRo1QlZWFn799VekpaUhOzsbAQEBCA8Px+uvv47NmzcjISEBx48fx3//+1/s2LHDoJqILJKcA36IyDSGDRsmXnjhhTK3zZ07V3h6ego7OzvRu3dvsWbNGgFA3L17VwihP4A1Ly9PDBkyRPj4+AiVSiW8vLzEO++8ozeI9tixY6JXr17C0dFRODg4iDZt2ohPPvmk3NrKGiD7sCVLlojGjRsLGxsbERAQINasWaPdtmXLFtGxY0fh7OwsHBwcRKdOncQvv/yi3f7wgOJt27aJpk2bCqVSKfz8/IQQpQcUl3jyyScFAPHbb7+V2masz3n16lWhVCpFdHS0EOLRvw8hhIiIiBD16tUTAMT06dOFEELk5+eLadOmiUaNGgkbGxvRoEEDMXDgQHHmzJlyayKqLRRCCCFvvCIiIiIyHl6WIiIiIovCcENEREQWheGGiIiILArDDREREVkUhhsiIiKyKAw3REREZFEYboiIiMiiMNwQERGRRWG4ISIiIovCcENEREQWheGGiIiILArDDREREVmU/we8yS9T5hLrxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ROC Curve for XGBoost\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test,y_pred)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr,tpr,color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGB ROC Curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing XGBoost to Linear SVM \n",
    "- XGBoost out performed the Linear SVM that resulted from hyperparameter tuning according to its F1 and AUC_ROC score.\n",
    "- The two models had similar Precision and Recall scores, but XGBoost still had the better score of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making submission file for Kaggle Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#importing test dataset provided by kaggle\n",
    "kaggle_test=pd.read_csv('test.csv') #need to import to get ID column\n",
    "input_test=cp.testdf_prep('test.csv') #function slightly different from load_preprocess_data(); accounts for no 'Exited' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Age/Tenure</th>\n",
       "      <th>Balance/Tenure</th>\n",
       "      <th>Balance/Age</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.804903</td>\n",
       "      <td>0.201754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604265</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362723</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.540284</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.694419</td>\n",
       "      <td>0.085213</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.599526</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.569654</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.767773</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.483318</td>\n",
       "      <td>0.697164</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.057261</td>\n",
       "      <td>0.312516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110018</th>\n",
       "      <td>0.336493</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.462737</td>\n",
       "      <td>0.740451</td>\n",
       "      <td>0.072682</td>\n",
       "      <td>0.078318</td>\n",
       "      <td>0.392066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110019</th>\n",
       "      <td>0.348341</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.709581</td>\n",
       "      <td>0.210871</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.210168</td>\n",
       "      <td>0.484309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110020</th>\n",
       "      <td>0.672986</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081387</td>\n",
       "      <td>0.271930</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110021</th>\n",
       "      <td>0.665877</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.794101</td>\n",
       "      <td>0.187135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110022</th>\n",
       "      <td>0.457346</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.350136</td>\n",
       "      <td>0.121006</td>\n",
       "      <td>0.092732</td>\n",
       "      <td>0.059260</td>\n",
       "      <td>0.232518</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110023 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore       Age   Balance  EstimatedSalary  Age/Tenure  \\\n",
       "0          0.374408  0.128205  0.000000         0.804903    0.201754   \n",
       "1          0.604265  0.717949  0.000000         0.362723    0.403509   \n",
       "2          0.540284  0.410256  0.000000         0.694419    0.085213   \n",
       "3          0.599526  0.461538  0.000000         0.569654    0.078947   \n",
       "4          0.767773  0.512821  0.483318         0.697164    0.066667   \n",
       "...             ...       ...       ...              ...         ...   \n",
       "110018     0.336493  0.282051  0.462737         0.740451    0.072682   \n",
       "110019     0.348341  0.461538  0.709581         0.210871    0.157895   \n",
       "110020     0.672986  0.333333  0.000000         0.081387    0.271930   \n",
       "110021     0.665877  0.358974  0.000000         0.794101    0.187135   \n",
       "110022     0.457346  0.487179  0.350136         0.121006    0.092732   \n",
       "\n",
       "        Balance/Tenure  Balance/Age    0    1    2  ...   14   15   16   17  \\\n",
       "0             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "1             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "2             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "3             0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "4             0.057261     0.312516  0.0  1.0  0.0  ...  0.0  1.0  1.0  0.0   \n",
       "...                ...          ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "110018        0.078318     0.392066  0.0  0.0  1.0  ...  0.0  0.0  1.0  0.0   \n",
       "110019        0.210168     0.484309  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "110020        0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  0.0  1.0   \n",
       "110021        0.000000     0.000000  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "110022        0.059260     0.232518  1.0  0.0  0.0  ...  0.0  0.0  1.0  0.0   \n",
       "\n",
       "         18   19   20   21   22   23  \n",
       "0       0.0  0.0  1.0  0.0  0.0  1.0  \n",
       "1       0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "2       0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "3       0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "4       0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "...     ...  ...  ...  ...  ...  ...  \n",
       "110018  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "110019  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "110020  0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "110021  0.0  0.0  0.0  1.0  0.0  1.0  \n",
       "110022  0.0  0.0  0.0  1.0  1.0  0.0  \n",
       "\n",
       "[110023 rows x 31 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking input_test df\n",
    "input_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110023,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using XGBoost model to predict Exited status\n",
    "submission_pred = best_model.predict(input_test)\n",
    "submission_pred.shape #checking that there are predictions for each customer (rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110018</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110019</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110020</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110021</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110022</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110023 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Exited\n",
       "0            0\n",
       "1            1\n",
       "2            0\n",
       "3            0\n",
       "4            0\n",
       "...        ...\n",
       "110018       0\n",
       "110019       0\n",
       "110020       0\n",
       "110021       0\n",
       "110022       0\n",
       "\n",
       "[110023 rows x 1 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning predictions into array\n",
    "submission_pred=pd.DataFrame(submission_pred,columns=['Exited'])\n",
    "submission_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110018</th>\n",
       "      <td>275052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110019</th>\n",
       "      <td>275053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110020</th>\n",
       "      <td>275054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110021</th>\n",
       "      <td>275055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110022</th>\n",
       "      <td>275056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110023 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id\n",
       "0       165034\n",
       "1       165035\n",
       "2       165036\n",
       "3       165037\n",
       "4       165038\n",
       "...        ...\n",
       "110018  275052\n",
       "110019  275053\n",
       "110020  275054\n",
       "110021  275055\n",
       "110022  275056\n",
       "\n",
       "[110023 rows x 1 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#selecting ID column\n",
    "kaggle_test=kaggle_test['id']\n",
    "kaggle_test=pd.DataFrame(kaggle_test,columns=['id'])\n",
    "kaggle_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110018</th>\n",
       "      <td>275052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110019</th>\n",
       "      <td>275053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110020</th>\n",
       "      <td>275054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110021</th>\n",
       "      <td>275055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110022</th>\n",
       "      <td>275056</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  Exited\n",
       "0       165034       0\n",
       "1       165035       1\n",
       "2       165036       0\n",
       "3       165037       0\n",
       "4       165038       0\n",
       "...        ...     ...\n",
       "110018  275052       0\n",
       "110019  275053       0\n",
       "110020  275054       0\n",
       "110021  275055       0\n",
       "110022  275056       0\n",
       "\n",
       "[110023 rows x 2 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining ID column and Exited status predictions into one df\n",
    "submission=pd.concat([kaggle_test,submission_pred],axis=1)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating submission file (csv file)\n",
    "submission.to_csv(\"churn_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
